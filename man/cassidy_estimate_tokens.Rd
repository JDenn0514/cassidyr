% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/context-tokens.R
\name{cassidy_estimate_tokens}
\alias{cassidy_estimate_tokens}
\title{Estimate token count from text}
\usage{
cassidy_estimate_tokens(
  text,
  safety_factor = 1.15,
  method = c("fast", "conservative", "optimistic")
)
}
\arguments{
\item{text}{Character vector. Text to estimate tokens for.}

\item{safety_factor}{Numeric. Multiply estimate by this factor for safety buffer.
Default 1.15 (15\% safety margin).}

\item{method}{Character. Estimation method:
\itemize{
\item "fast": Simple char count / 3 (default)
\item "conservative": Assumes 2.5:1 ratio (more conservative)
\item "optimistic": Assumes 3.5:1 ratio (for prose-heavy content)
}}
}
\value{
Integer. Estimated token count.
}
\description{
Uses empirically-determined character-to-token ratio with safety buffer.
CassidyAI uses Claude Sonnet 4.5 which has ~3:1 char-to-token ratio for
typical mixed content (code, prose, structured data).
}
\examples{
text <- "The quick brown fox jumps over the lazy dog."
cassidy_estimate_tokens(text)

# With conservative estimate
cassidy_estimate_tokens(text, method = "conservative")

# Multiple text elements are collapsed
cassidy_estimate_tokens(c("Hello", "world"))
}
